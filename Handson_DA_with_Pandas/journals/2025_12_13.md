## Chapter3
The use case of pandas data cleaning
	- #### Read file
	  more info check [link](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)
		- ```
		  pd.read_csv(use_col=[],parse_dates=['column of date'])
		  ```
	- #### Plot data
		- matplotlib.pyplot 
		  ```
		  from matplotlib import pyplot as plt
		  wide_df.plot(
		  x='date', y=['TMAX', 'TMIN', 'TOBS'], figsize=(15, 5), 
		  title='Temperature in NYC in October 2018'
		  ).set_ylabel('Temperature in Celsius')
		  plt.show()
		  ```
		- seaborn 
		  ```
		  import seaborn as sns
		  
		  sns.set(rc={'figure.figsize': (15, 5)}, style='white')
		  
		  ax = sns.lineplot(
		      data=long_df, x='date', y='value', hue='datatype'
		  )
		  ax.set_ylabel('Temperature in Celsius')
		  ax.set_title('Temperature in NYC in October 2018')
		  plt.show()
		  ```
		- using pandas build in plot function to plot data
		  ```
		  ax = df['range1':'range2'].plot(y= 'xxx',
		                                  figsize = (15,5),
		                                  legend = False,
		                                  title = 'xxxxxxxxyyyyyyy')
		  # formatting 
		  ax.set_ylabel('xxx')
		  
		  ## set the data format as $aaa,aaa
		  ax.yaxix.set_major_formatter(StrMethodFormatter('${x:,.0f}'))
		  
		  ## make the top and right border line invisable
		  for spine in ['top', 'right']:
		      ax.spines[spine].set_visible(False)
		      
		  # show the plot
		  plt.show()
		  ```
	- #### Connect to API Basic Function Structure
	  ```
	  import requests
	  
	  def make_request(endpoint, payload=None):
	      """
	      Make a request to a specific endpoint on the weather API
	      passing headers and optional payload.
	      
	      Parameters:
	          - endpoint: The endpoint of the API you want to 
	                      make a GET request to.
	          - payload: A dictionary of data to pass along 
	                     with the request. for example
	                         {
	                            'datasetid': 'GHCND',
	                            'stationid': central_park['id'],
	                            'locationid': nyc['id'],
	                            'startdate': '2018-10-01',
	                            'enddate': '2018-10-31',
	                            'datatypeid': ['TAVG', 'TMAX', 'TMIN'],
	                            'units': 'metric',
	                            'limit': 1000
	                          }
	      
	      Returns:
	          A response object.
	      """
	      return requests.get(
	          f'https://www.ncdc.noaa.gov/cdo-web/api/v2/{endpoint}',
	          headers={
	              'token': ''
	          },
	          params=payload
	      )
	  ```
	- ### Data clean basics
		- #### Rename, Convert Object
		  ```
		  df.rename(
		      columns={
		          'old_col_name': 'new_col_name',
		      }, inplace=True
		  )
		  
		  # transfer the date from 10-25 to east time zone, the frequent is Day
		  pd.date_range(start='2018-10-25', periods=2, freq='D').tz_localize('EST')
		  
		  # covert DatetimeIndex object to desired timezones
		  eastern = pd.read_csv(
		      'data/nyc_temperatures.csv', index_col='date', parse_dates=True
		  ).tz_localize('EST')
		  
		  # change to `PeriodIndex (monthly)` and change it to DatatimeIndex
		  eastern.tz_localize(None).to_period('M').to_timestamp().index
		  ```
		- ####  `DatetimeIndex`
		  Index of type `DatetimeIndex`, enabling to  datetime slicing and indexing. we can use the datetime as index, and searching data using loc['datetime1':'datetime2']
			- example: 
			  all of 2018,  `df.loc['2018']`,
			  fourth quarter of 2018 `df.loc['2018-Q4']`, 
			  October is as simple `df.loc['2018-10']`; 
			  these can also be combined to build ranges.
		- ####  Reordering, Reindering and sorting
		  ```
		  # slicing the data by conditin and sort by other columns' values
		  ## if ignore_index means it assigns new index after sorting 
		  df[df.datatype == 'value1'].sort_values(by=['col2', 'col3'], 
		                            ascending=[False, True], 
		                            ignore_index=True).head(10)
		                            
		  # if just want to check the n largest / smallest values 
		  df[df.col2 == 'value2'].nlargest(n=10, columns='col3')
		  df[df.col4 == 'value4'].nsmallest(n=10, columns='col2')
		  
		  # get random sample
		  df.sample(5, random_state=0).sort_index()
		  
		  # reset index
		  df.set_index('date', inplace=True)
		  ## we can set date as index when import from csv
		  df = pd.read_csv(index_col='date', delimiter=',',parse_dates=True)
		  
		  # select specific cols when import 
		  df = pd.read_csv(usecols=[list of column names])
		  ## or drop columns
		  df = pd.read_csv(...).drop(columns=[list of column names])
		  
		  # concat and group data
		  portfolio = pd.concat([sp, bitcoin], sort=False).groupby(level='date').sum()
		  portfolio.head(10).assign(
		      day_of_week=lambda x: x.index.day_name()
		  )
		  ```
		- ### Reshaping Data
			- ### Pivoting
			  Going from long to wide format.
				- `pivot()`
				  We can restructure our data by picking a column to go in the index (`index`), a column whose unique values will become column names (`columns`), and the values to place in those columns (`values`). The `pivot()` method can be used when we don't need to perform any aggregation in addition to our restructuring (when our index is unique); if this is not the case, we need the `pivot_table()` method
				  ```
				  # This example pivoted the table by the column datetype, 
				  it creates the new columns with name from datetype and 
				  with the values of 'temp_C'
				  
				  pivoted_df = long_df.pivot(
				      index='date', columns='datetype', values='temp_C'
				  )
				  pivoted_df.head()
				  
				  ```
				- `unstack()`
				  create an index from any number of columns with `set_index()`. which is`MultiIndex`, where the outermost level corresponds to the first element in the list provided to `set_index()`.
				  With an index of type `MultiIndex`, we can no longer use `pivot()`. We must now use `unstack()`, which by default moves the innermost index onto the columns:
				  ```
				  multi_index_df = long_df.set_index(['date', 'datatype'])
				  unstacked_df = multi_index_df.unstack()
				  ## fill value for NaN data
				  extra_data.unstack(fill_value=-40).head()
				  ```
			- ### Melting
			  Going from wide to long format.
			  ```
			  melted_df = wide_df.melt(
			      id_vars='date',
			      value_vars=['TMAX', 'TMIN', 'TOBS'],
			      value_name='temp_C',
			      var_name='measurement'
			  )
			  melted_df.head()
			  ````
			  id_vars`: which column(s) uniquely identify a row in the wide format (`date`, here)
			  value_vars`: the column(s) that contain(s) the values (`TMAX`, `TMIN`, and `TOBS`, here)
			  Optionally, we can also provide 
			  'value_name`: what to call the column that will contain all the values once melted `var_name`: what to call the column that will contain the names of the variables being measured
			-